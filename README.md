INTRODUCTION

In this project we use the concept of entropy, specifically
as defined in information theory, to rate various securities in
terms of their risk. Entropy quantifies how much is not
known in an event, uncertainty. A difference between
entropy and information is that entropy measures the
unknown, and information is the known part. Information
allows us to make a more accurate prediction about a
future event, in this case the stock market. We use two
approaches to test the data. First, we look for patterns in
when the security increased in price (coded as 1) or
decreased (coded as 0). In the second approach we tested
the data in 5 levels, considering changes in the stock price as
a dramatic decrease (coded as 0), slight decrease (1),
relatively unchanged (2), slight increase (3), and dramatic
increase (4). The first approach did not significantly reduce
the entropy compared to a random sequence, whereas the
second approach gives us more information making the
stock price for certain companies more predictable, that is
less risky, than others.

![SPRING Research Presentation](https://user-images.githubusercontent.com/20369540/221332631-2b3a9632-9b35-43a6-a31a-cd10b3ef55a7.png)

The entire project explanation with its results is on the PDF link:
[Project - PDF](https://drive.google.com/file/d/1FSWzZ--UneA1kbEsc3v3Pqk6b2j22W3k/view?usp=sharing)
